{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Anomaly Detection and its Purpose\n",
        "\n",
        "Anomaly detection is the process of finding items, events, or observations that differ significantly from the established patterns or behaviors in data.\n",
        "Purpose: Identify suspicious activity, potential equipment failures, fraudulent transactions, or any unexpected deviation that might require further investigation.\n",
        "Q2. Challenges in Anomaly Detection\n",
        "\n",
        "Defining Normal vs. Anomaly: What constitutes \"normal\" can be subjective and can change over time.\n",
        "Rare Events: Anomalies are often infrequent, making it difficult to train models and evaluate their effectiveness.\n",
        "High-dimensionality: Data can have many features, increasing the complexity of identifying anomalies.\n",
        "Concept Drift: The underlying patterns in data may change over time, requiring continuous adaptation of the detection methods.\n",
        "Q3. Unsupervised vs. Supervised Anomaly Detection\n",
        "\n",
        "Unsupervised: No pre-labeled data on what constitutes an anomaly. The algorithm learns the \"normal\" patterns and identifies deviations. (More common)\n",
        "Supervised: Requires labeled data with examples of both normal and anomalous data points. The model learns to classify new data points. (Less common due to data scarcity)\n",
        "Q4. Categories of Anomaly Detection Algorithms\n",
        "\n",
        "Distance-based: Identify anomalies as data points far away from the majority in terms of a distance metric (e.g., Euclidean distance)\n",
        "Statistical: Use statistical methods to model normal behavior and identify deviations from the expected distribution (e.g., outlier detection using standard deviation)\n",
        "Density-based: Focus on the local density of data points. Anomalies are points in areas with sparse density compared to the core clusters. (e.g., Local Outlier Factor (LOF))\n",
        "Isolation Forest: Anomalies are isolated points that can be easily separated from the rest of the data through random partitioning of features.\n",
        "Q5. Assumptions of Distance-based Methods\n",
        "\n",
        "The underlying data resides in a low-dimensional space.\n",
        "There's a well-defined notion of distance between data points.\n",
        "The distribution of normal data points is well-understood.\n",
        "Q6. LOF (Local Outlier Factor) Anomaly Scores\n",
        "\n",
        "LOF compares the local density of a data point with the density of its neighbors. Higher LOF scores indicate higher anomaly scores. It considers the ratio of the average local density of its neighbors to its own local density.\n",
        "\n",
        "Q7. Key Parameters of Isolation Forest\n",
        "\n",
        "Number of trees (n_estimators): Higher values lead to more accurate anomaly scores but take longer to train.\n",
        "Contamination: The proportion of anomalies in the data (used for parameter tuning in some implementations).\n",
        "Max samples: The number of features randomly chosen for splitting at each node in the tree.\n",
        "Q8. KNN Anomaly Score with K=10 and 2 Neighbors\n",
        "\n",
        "K-Nearest Neighbors (KNN) doesn't directly output anomaly scores. However, in anomaly detection with KNN, you can consider the distance to the Kth nearest neighbor as an anomaly score. With K=10 and only 2 neighbors within a radius of 0.5, this data point might be considered an anomaly due to the lack of closer neighbors.\n",
        "\n",
        "Q9. Isolation Forest Anomaly Score\n",
        "\n",
        "Isolation Forest assigns anomaly scores between 0 (likely normal) and 1 (likely anomaly).  Here, we lack information about the average path length of the entire dataset. However, a data point with an average path length of 5.0 compared to the average path length of the trees could be an anomaly if the average path length for most data points is significantly lower. Lower path lengths indicate easier isolation, suggesting a potential anomaly."
      ],
      "metadata": {
        "id": "XmmAaHOyQRoI"
      }
    }
  ]
}